import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import t, jarque_bera, shapiro, kstest
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

# Configuration de la page
st.set_page_config(
    page_title="Analyse Distribution Student-t et Rendements",
    page_icon="üìä",
    layout="wide"
)

st.title("üìä Analyse de la Distribution Student-t et Pr√©vision des Rendements")
st.markdown("---")

# Fonction pour charger et pr√©parer les donn√©es
@st.cache_data
def load_and_prepare_data(uploaded_file=None):
    """Charge et pr√©pare les donn√©es de prix"""
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
    else:
        # Donn√©es par d√©faut (extrait de votre CSV)
        data = """Date, Open, High, Low, Close, Volume
06/13/25, 25000, 24900, 24900, 24900, 21005
06/12/25, 25000, 25000, 25000, 25000, 19553
06/11/25, 25000, 25000, 25000, 25000, 35662
06/10/25, 25000, 25000, 25000, 25000, 19045
06/05/25, 25000, 25000, 25000, 25000, 5889
06/04/25, 25000, 25000, 25000, 25000, 73169"""
        
        from io import StringIO
        df = pd.read_csv(StringIO(data))
    
    # Nettoyer les noms de colonnes
    df.columns = df.columns.str.strip()
    
    # Convertir la date
    df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%y')
    
    # Trier par date
    df = df.sort_values('Date').reset_index(drop=True)
    
    # Calculer les rendements
    df['Returns'] = df['Close'].pct_change()
    df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))
    
    # Supprimer les valeurs NaN
    df = df.dropna()
    
    return df

# Fonction pour tester la distribution Student-t
def test_student_t_distribution(returns):
    """Teste si les rendements suivent une distribution Student-t"""
    
    # √âliminer les outliers extr√™mes
    q1, q3 = np.percentile(returns, [25, 75])
    iqr = q3 - q1
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr
    
    clean_returns = returns[(returns >= lower_bound) & (returns <= upper_bound)]
    
    # Ajuster une distribution Student-t
    params_t = stats.t.fit(clean_returns)
    df_t, loc_t, scale_t = params_t
    
    # Ajuster une distribution normale pour comparaison
    params_norm = stats.norm.fit(clean_returns)
    loc_norm, scale_norm = params_norm
    
    # Tests statistiques
    # Test de Kolmogorov-Smirnov pour Student-t
    ks_stat_t, ks_p_t = stats.kstest(clean_returns, lambda x: stats.t.cdf(x, df_t, loc_t, scale_t))
    
    # Test de Kolmogorov-Smirnov pour distribution normale
    ks_stat_norm, ks_p_norm = stats.kstest(clean_returns, lambda x: stats.norm.cdf(x, loc_norm, scale_norm))
    
    # Test de Jarque-Bera (normalit√©)
    jb_stat, jb_p = jarque_bera(clean_returns)
    
    # Calcul de l'AIC pour comparaison
    log_likelihood_t = np.sum(stats.t.logpdf(clean_returns, df_t, loc_t, scale_t))
    log_likelihood_norm = np.sum(stats.norm.logpdf(clean_returns, loc_norm, scale_norm))
    
    aic_t = -2 * log_likelihood_t + 2 * 3  # 3 param√®tres pour Student-t
    aic_norm = -2 * log_likelihood_norm + 2 * 2  # 2 param√®tres pour normale
    
    return {
        'params_t': params_t,
        'params_norm': params_norm,
        'ks_test_t': (ks_stat_t, ks_p_t),
        'ks_test_norm': (ks_stat_norm, ks_p_norm),
        'jarque_bera': (jb_stat, jb_p),
        'aic_t': aic_t,
        'aic_norm': aic_norm,
        'clean_returns': clean_returns
    }

# Fonction pour calculer les niveaux de rendement
def calculate_return_levels(returns, distribution_params, dist_type='t'):
    """Calcule les niveaux de rendement attendus"""
    
    if dist_type == 't':
        df_param, loc, scale = distribution_params
        distribution = stats.t(df_param, loc, scale)
    else:
        loc, scale = distribution_params
        distribution = stats.norm(loc, scale)
    
    # Niveaux de confiance
    confidence_levels = [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]
    
    quantiles = {}
    for conf in confidence_levels:
        quantiles[f'{conf*100:.0f}%'] = distribution.ppf(conf)
    
    # VaR et CVaR
    var_95 = distribution.ppf(0.05)
    var_99 = distribution.ppf(0.01)
    
    # CVaR (Expected Shortfall)
    x_range = np.linspace(distribution.ppf(0.001), var_95, 1000)
    cvar_95 = np.trapz(x_range * distribution.pdf(x_range), x_range) / distribution.cdf(var_95)
    
    x_range_99 = np.linspace(distribution.ppf(0.001), var_99, 1000)
    cvar_99 = np.trapz(x_range_99 * distribution.pdf(x_range_99), x_range_99) / distribution.cdf(var_99)
    
    return {
        'quantiles': quantiles,
        'var_95': var_95,
        'var_99': var_99,
        'cvar_95': cvar_95,
        'cvar_99': cvar_99,
        'expected_return': distribution.mean(),
        'volatility': distribution.std()
    }

# Interface utilisateur
st.sidebar.header("üìÅ Chargement des donn√©es")
uploaded_file = st.sidebar.file_uploader(
    "Charger un fichier CSV", 
    type=['csv'],
    help="Format attendu: Date, Open, High, Low, Close, Volume"
)

# Charger les donn√©es
df = load_and_prepare_data(uploaded_file)

# Affichage des informations de base
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("Nombre d'observations", len(df))
with col2:
    st.metric("P√©riode", f"{df['Date'].min().strftime('%m/%Y')} - {df['Date'].max().strftime('%m/%Y')}")
with col3:
    st.metric("Prix moyen", f"{df['Close'].mean():.2f}")
with col4:
    st.metric("Volatilit√© (std)", f"{df['Returns'].std():.4f}")

# Analyse de la distribution
st.header("üîç Test de la Distribution Student-t")

returns = df['Log_Returns'].dropna()
test_results = test_student_t_distribution(returns)

# R√©sultats des tests
col1, col2 = st.columns(2)

with col1:
    st.subheader("üìä Tests Statistiques")
    
    # Test de Jarque-Bera
    jb_stat, jb_p = test_results['jarque_bera']
    if jb_p < 0.05:
        st.error(f"‚ùå Test Jarque-Bera: p-value = {jb_p:.4f} (Rejet de la normalit√©)")
    else:
        st.success(f"‚úÖ Test Jarque-Bera: p-value = {jb_p:.4f} (Non-rejet de la normalit√©)")
    
    # Test KS pour Student-t
    ks_stat_t, ks_p_t = test_results['ks_test_t']
    if ks_p_t > 0.05:
        st.success(f"‚úÖ KS Test (Student-t): p-value = {ks_p_t:.4f} (Bonne ad√©quation)")
    else:
        st.warning(f"‚ö†Ô∏è KS Test (Student-t): p-value = {ks_p_t:.4f} (Ad√©quation questionnable)")
    
    # Test KS pour Normale
    ks_stat_norm, ks_p_norm = test_results['ks_test_norm']
    if ks_p_norm > 0.05:
        st.success(f"‚úÖ KS Test (Normale): p-value = {ks_p_norm:.4f} (Bonne ad√©quation)")
    else:
        st.warning(f"‚ö†Ô∏è KS Test (Normale): p-value = {ks_p_norm:.4f} (Ad√©quation questionnable)")

with col2:
    st.subheader("üìà Comparaison des Mod√®les")
    
    aic_t = test_results['aic_t']
    aic_norm = test_results['aic_norm']
    
    st.write(f"**AIC Student-t:** {aic_t:.2f}")
    st.write(f"**AIC Normale:** {aic_norm:.2f}")
    
    if aic_t < aic_norm:
        st.success("üèÜ **Student-t est le meilleur mod√®le** (AIC plus faible)")
        best_model = 't'
    else:
        st.info("üèÜ **Distribution Normale est le meilleur mod√®le** (AIC plus faible)")
        best_model = 'norm'
    
    # Param√®tres de la distribution Student-t
    df_param, loc_t, scale_t = test_results['params_t']
    st.write(f"**Param√®tres Student-t:**")
    st.write(f"- Degr√©s de libert√©: {df_param:.2f}")
    st.write(f"- Location: {loc_t:.4f}")
    st.write(f"- Scale: {scale_t:.4f}")

# Graphiques de distribution
st.header("üìä Visualisation des Distributions")

fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=('Distribution des Rendements', 'Q-Q Plot Student-t', 
                   'Q-Q Plot Normal', 'Densit√© des Distributions'),
    specs=[[{"secondary_y": False}, {"secondary_y": False}],
           [{"secondary_y": False}, {"secondary_y": False}]]
)

clean_returns = test_results['clean_returns']

# Histogramme
fig.add_trace(
    go.Histogram(x=clean_returns, nbinsx=50, name='Donn√©es', opacity=0.7),
    row=1, col=1
)

# Q-Q Plot Student-t
df_param, loc_t, scale_t = test_results['params_t']
theoretical_quantiles_t = stats.t.ppf(np.linspace(0.01, 0.99, len(clean_returns)), df_param, loc_t, scale_t)
sample_quantiles = np.sort(clean_returns)

fig.add_trace(
    go.Scatter(x=theoretical_quantiles_t, y=sample_quantiles, mode='markers', name='Student-t Q-Q'),
    row=1, col=2
)
fig.add_trace(
    go.Scatter(x=[min(theoretical_quantiles_t), max(theoretical_quantiles_t)], 
              y=[min(theoretical_quantiles_t), max(theoretical_quantiles_t)], 
              mode='lines', name='Ligne th√©orique', line=dict(color='red')),
    row=1, col=2
)

# Q-Q Plot Normal
loc_norm, scale_norm = test_results['params_norm']
theoretical_quantiles_norm = stats.norm.ppf(np.linspace(0.01, 0.99, len(clean_returns)), loc_norm, scale_norm)

fig.add_trace(
    go.Scatter(x=theoretical_quantiles_norm, y=sample_quantiles, mode='markers', name='Normal Q-Q'),
    row=2, col=1
)
fig.add_trace(
    go.Scatter(x=[min(theoretical_quantiles_norm), max(theoretical_quantiles_norm)], 
              y=[min(theoretical_quantiles_norm), max(theoretical_quantiles_norm)], 
              mode='lines', name='Ligne th√©orique', line=dict(color='red')),
    row=2, col=1
)

# Comparaison des densit√©s
x_range = np.linspace(clean_returns.min(), clean_returns.max(), 1000)
pdf_t = stats.t.pdf(x_range, df_param, loc_t, scale_t)
pdf_norm = stats.norm.pdf(x_range, loc_norm, scale_norm)

fig.add_trace(
    go.Scatter(x=x_range, y=pdf_t, mode='lines', name='Student-t PDF'),
    row=2, col=2
)
fig.add_trace(
    go.Scatter(x=x_range, y=pdf_norm, mode='lines', name='Normal PDF'),
    row=2, col=2
)

fig.update_layout(height=800, showlegend=True, title_text="Analyse Comparative des Distributions")
st.plotly_chart(fig, use_container_width=True)

# Calcul des niveaux de rendement
st.header("üí∞ Niveaux de Rendement Attendus")

if best_model == 't':
    return_levels = calculate_return_levels(returns, test_results['params_t'], 't')
    st.success("üéØ Calculs bas√©s sur la distribution **Student-t** (meilleur mod√®le)")
else:
    return_levels = calculate_return_levels(returns, test_results['params_norm'], 'norm')
    st.info("üéØ Calculs bas√©s sur la distribution **Normale** (meilleur mod√®le)")

col1, col2, col3 = st.columns(3)

with col1:
    st.subheader("üìä Statistiques Principales")
    st.metric("Rendement Esp√©r√©", f"{return_levels['expected_return']:.4f}")
    st.metric("Volatilit√©", f"{return_levels['volatility']:.4f}")

with col2:
    st.subheader("‚ö†Ô∏è Value at Risk (VaR)")
    st.metric("VaR 95%", f"{return_levels['var_95']:.4f}")
    st.metric("VaR 99%", f"{return_levels['var_99']:.4f}")

with col3:
    st.subheader("üí• Conditional VaR (CVaR)")
    st.metric("CVaR 95%", f"{return_levels['cvar_95']:.4f}")
    st.metric("CVaR 99%", f"{return_levels['cvar_99']:.4f}")

# Tableau des quantiles
st.subheader("üìã Quantiles de Rendement")
quantiles_df = pd.DataFrame(list(return_levels['quantiles'].items()), 
                           columns=['Niveau de Confiance', 'Rendement'])
quantiles_df['Rendement (%)'] = quantiles_df['Rendement'] * 100

st.dataframe(quantiles_df, use_container_width=True)

# Interpr√©tation et recommandations
st.header("üéØ Interpr√©tation et Recommandations")

col1, col2 = st.columns(2)

with col1:
    st.subheader("üìù R√©sum√© de l'Analyse")
    
    if best_model == 't':
        st.write("""
        **‚úÖ La distribution Student-t est appropri√©e pour vos donn√©es**
        
        - Les rendements pr√©sentent des queues plus √©paisses qu'une distribution normale
        - Le mod√®le Student-t capture mieux les √©v√©nements extr√™mes
        - Les tests statistiques confirment une meilleure ad√©quation
        """)
    else:
        st.write("""
        **‚ÑπÔ∏è La distribution Normale semble suffisante**
        
        - Les rendements suivent approximativement une distribution normale
        - Pas de queues particuli√®rement √©paisses d√©tect√©es
        - Le mod√®le normal est plus simple et appropri√©
        """)

with col2:
    st.subheader("‚ö° Recommandations")
    
    if return_levels['expected_return'] > 0:
        st.success(f"üìà **Tendance positive**: Rendement esp√©r√© de {return_levels['expected_return']*100:.2f}%")
    else:
        st.warning(f"üìâ **Tendance n√©gative**: Rendement esp√©r√© de {return_levels['expected_return']*100:.2f}%")
    
    volatility_level = return_levels['volatility']
    if volatility_level > 0.02:
        st.error("üî• **Volatilit√© √©lev√©e**: Investissement risqu√©")
    elif volatility_level > 0.01:
        st.warning("‚ö†Ô∏è **Volatilit√© mod√©r√©e**: Risque mod√©r√©")
    else:
        st.success("‚úÖ **Faible volatilit√©**: Investissement relativement stable")

# Footer
st.markdown("---")
st.markdown("""
**Note**: Cette analyse est bas√©e sur les donn√©es historiques et ne constitue pas un conseil financier. 
Les performances pass√©es ne pr√©jugent pas des performances futures.
""")
